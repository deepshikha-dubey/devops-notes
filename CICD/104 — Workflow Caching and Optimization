104 — Workflow Caching and Optimization
Speed up CI/CD pipelines with intelligent caching strategies. Learn dependency caching, Docker layer caching, and workflow optimization techniques to reduce build times.

Step 1 Measure baseline performance
Establish current workflow speed before optimization.

Commands to Run
cd cicd-testing
gh run list --limit 5 --json durationMs,name,conclusion
gh run list --limit 5 --json name,conclusion,startedAt,updatedAt(in window)
gh run view --log | grep 'Elapsed time'

What This Does
Before optimizing, measure current performance. GitHub tracks duration of each step and total workflow time.

Expected Outcome
You'll see workflow durations, likely 2-4 minutes total. 'Install dependencies' step probably takes 30-60 seconds.

Pro Tips
1 Baseline metrics help prove optimization effectiveness
2 Focus on slowest steps first for biggest impact
3 Dependency installation is usually the slowest step
4 Track improvements after each optimization

Step 2 Add npm caching to workflow
Cache node_modules to speed up subsequent runs.

Commands to Run
cat > .github/workflows/cached-test.yml << 'EOF'
name: Cached Tests

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Node.js with caching
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Run tests
      run: npm test
EOF

git add .github/workflows/cached-test.yml
git commit -m 'Add npm caching'
git push
gh run watch

What This Does
The cache: 'npm' option automatically caches npm dependencies based on package-lock.json. Subsequent runs restore cache instead of downloading everything.

Expected Outcome
First run: cache miss, downloads all dependencies. Second run: cache hit, 'Install dependencies' completes in ~5 seconds instead of 30-60.

Pro Tips
1 setup-node@v4 handles npm caching automatically
2 Cache invalidates when package-lock.json changes
3 Saves bandwidth and time on every run
4 Works with npm, yarn, and pnpm
5 GitHub provides 10GB cache storage per repository

Step 3 Implement manual caching with actions/cache
Use the cache action for fine-grained control over what gets cached.

Commands to Run
cat > .github/workflows/manual-cache.yml << 'EOF'
name: Manual Cache

on:
  push:
    branches: [ main ]

jobs:
  build:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
    
    - name: Cache node modules
      id: cache-npm
      uses: actions/cache@v4
      with:
        path: node_modules
        key: ${{ runner.os }}-node-${{ hashFiles('package-lock.json') }}
        restore-keys: |
          ${{ runner.os }}-node-
    
    - name: Install dependencies
      if: steps.cache-npm.outputs.cache-hit != 'true'
      run: npm ci
    
    - name: Run tests
      run: npm test

cat .github/workflows/manual-cache.yml

What This Does
actions/cache provides explicit control. Key uses OS and package-lock.json hash. If match found, npm ci is skipped entirely. restore-keys provides fallback partial matches.

Expected Outcome
Workflow created with conditional npm ci step. On cache hit, installation is completely skipped, saving 30+ seconds.

Pro Tips
1 Cache key should include anything that invalidates the cache
2 hashFiles() creates hash of file contents
3 restore-keys try partial matches if exact key not found
4 outputs.cache-hit tells if cache was restored
5 Multiple paths can be cached in one action


Step 4 Cache multiple directories
Cache build outputs and downloaded tools.

Commands to Run
cat > .github/workflows/multi-cache.yml << 'EOF'
name: Multi-level Cache
on: push
jobs:
  build:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Cache multiple paths
      uses: actions/cache@v4
      with:
        path: |
          ~/.npm
          node_modules
          dist
        key: ${{ runner.os }}-multi-${{ hashFiles('package-lock.json') }}
        restore-keys: |
          ${{ runner.os }}-multi-
    
    - uses: actions/setup-node@v4
      with:
        node-version: '20'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Build project
      run: |
        mkdir -p dist
        cp *.js package.json dist/

cat .github/workflows/multi-cache.yml

What This Does
Cache multiple directories with | (pipe) syntax. Caches npm's cache directory (~/.npm), dependencies (node_modules), and build output (dist).

Expected Outcome
Workflow caches three directories. Subsequent runs restore all three if package-lock.json unchanged.

Pro Tips
1 Use | for multiline path list
2 Cache common directories: ~/.npm, ~/.cargo, ~/.m2
3 Include build outputs if they're expensive to regenerate
4 Don't cache files that change every run
5 Order paths from least to most specific

Step 5 Optimize with sparse checkout
Check out only necessary files for faster cloning.

Commands to Run
cat > .github/workflows/sparse-checkout.yml << 'EOF'
name: Sparse Checkout

on: push

jobs:
  docs:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
      with:
        sparse-checkout: |
          docs
          README.md
        sparse-checkout-cone-mode: false
    
    - name: List checked out files
      run: ls -la

cat .github/workflows/sparse-checkout.yml

What This Does
Sparse checkout only downloads specified directories/files. Useful for large repos when you only need a subset. Dramatically faster for monorepos.

Expected Outcome
Checkout only includes docs/ and README.md. Other files not downloaded, saving time and disk space.

Pro Tips
1 Use for large repositories (>1GB)
2 Specify only paths needed for the job
3 Reduces clone time and disk usage
4 cone-mode: false allows flexible path patterns
5 Not beneficial for small repositories

Step 6 Parallelize independent jobs
Run jobs concurrently to reduce total pipeline time.

Commands to Run
cat > .github/workflows/parallel.yml << 'EOF'
name: Parallel Pipeline

on: push

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
    - run: npm ci
    - run: npm run lint
  
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
    - run: npm ci
    - run: npm test
  
  security:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
    - run: npm ci
    - run: npm audit --audit-level=high
  
  deploy:
    runs-on: ubuntu-latest
    needs: [lint, test, security]
    steps:
    - run: echo "All checks passed, ready to deploy"

git add .github/workflows/parallel.yml
git commit -m 'Add parallel workflow'
git push
gh run watch

What This Does
Lint, test, and security scans run in parallel (no dependencies). Deploy waits for all three with needs: [lint, test, security]. Three jobs finish in time of slowest, not sum of all.

Expected Outcome
Three jobs start simultaneously. When all pass, deploy runs. Total time ~= slowest job, not sum of all jobs.

Pro Tips
1 Parallelize independent jobs for maximum speed
2 Each parallel job uses a separate runner
3 Free tier allows up to 20 concurrent jobs
4 needs: creates execution dependencies
5 Parallel jobs share no state - each starts fresh

Step 7 Skip unnecessary workflow runs
Prevent workflows from running on irrelevant changes.

Commands to Run
cat > .github/workflows/path-filtering.yml << 'EOF'
name: Path Filtered

on:
  push:
    branches: [ main ]
    paths:
      - 'src/**'
      - 'package.json'
      - 'package-lock.json'
      - '.github/workflows/**'

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - run: echo "Code changed, building..."

git add .github/workflows/path-filtering.yml
git commit -m 'Add path filtering'
git push
echo '# Documentation' > docs.md
git add docs.md
git commit -m 'Update docs'
git push
gh run list --limit 3

What This Does
paths: filter runs workflow only when specified files change. Updating docs.md doesn't trigger this workflow. Saves CI minutes and reduces noise.

Expected Outcome
First push (adding workflow) triggers run. Second push (docs.md) doesn't trigger because docs.md isn't in paths filter.

Pro Tips
1 Use paths: to avoid unnecessary runs
2 Specify source code, dependencies, workflow files
3 Wildcards supported: src/**, *.js
4 paths-ignore: excludes patterns instead
5 Combine with branches: for fine control
6 Saves CI minutes on large teams


Step 8 Use concurrency limits
Cancel redundant workflow runs automatically.

Commands to Run
cat > .github/workflows/concurrency.yml << 'EOF'
name: Concurrency Control

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
    - run: npm ci
    - run: npm test

cat .github/workflows/concurrency.yml

What This Does
Concurrency group based on workflow name and git ref. If you push twice quickly, second push cancels first in-progress run. Saves time testing outdated code.

Expected Outcome
Rapid consecutive pushes cancel earlier runs. Only most recent push completes. Prevents waste of CI minutes on outdated code.

Pro Tips
1 Perfect for rapidly iterating on PRs
2 Group by: workflow + ref ensures each PR/branch independent
3 cancel-in-progress: true stops old runs
4 Without this, all runs complete even if superseded
5 Particularly useful with long-running workflows

Step 9 Optimize Docker builds with layer caching
Cache Docker layers in CI for faster image builds.

Commands to Run
cat > Dockerfile << 'EOF'
FROM node:20-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --production
COPY . .
CMD ["node", "server.js"]
EOF
Copy
cat > .github/workflows/docker-cache.yml << 'EOF'
name: Docker with Cache

on: push

jobs:
  docker:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build with cache
      uses: docker/build-push-action@v5
      with:
        context: .
        push: false
        tags: myapp:latest
        cache-from: type=gha
        cache-to: type=gha,mode=max

git add Dockerfile .github/workflows/docker-cache.yml
git commit -m 'Add Docker build with caching'
git push

What This Does
Buildx with GitHub Actions cache (type=gha) caches Docker layers. Second build reuses unchanged layers (node:20-alpine, npm ci) and only rebuilds changed layers.

Expected Outcome
First build: downloads base image, installs deps (~2-3 min). Second build: cache hits on unchanged layers (~30 sec).

Pro Tips
1 type=gha uses GitHub's cache backend
2 mode=max caches all intermediate layers
3Order Dockerfile: least changed (base) to most changed (code)
4 COPY package.json before COPY . . for better caching
5 Buildx required for advanced caching features

Step 10 Monitor cache effectiveness
Measure cache hit rates and storage usage.

Commands to Run
gh cache list
gh api repos/$(gh repo view --json nameWithOwner -q .nameWithOwner)/actions/cache/usage
gh cache delete --all

What This Does
GitHub API provides cache usage statistics. gh cache commands manage caches. Monitor hit rates to validate optimization effectiveness.

Expected Outcome
Cache usage shows size and hit rate. List displays all caches with keys and sizes. Delete removes stale caches to free space.

Pro Tips
1 10GB cache limit per repository
2 Least recently used caches evicted when limit reached
3 High hit rate (>80%) indicates effective caching
4 Delete old caches manually if approaching limit
5 Cache keys should be stable but invalidate when needed

Step 11 Compare before and after performance
Measure optimization impact on workflow speed.

Commands to Run
gh run list --workflow='Test Suite' --limit 5 --json durationMs,conclusion
gh run list --workflow='Cached Tests' --limit 5 --json durationMs,conclusion

What This Does
Compare workflow durations before and after caching. Typically see 40-60% reduction in total time, primarily from faster dependency installation.

Expected Outcome
Uncached: 2-4 minutes total. Cached: 1-2 minutes total. 'Install dependencies' drops from 30-60s to 5-10s.

Pro Tips
1 Measure multiple runs for accurate averages
2 Cache hit rate improves over time as cache warms up
3 First run after cache invalidation is slower
4 Track improvements with baseline metrics
5 Diminishing returns after initial optimizations

Step 12 Best practices summary
Review optimization strategies and when to use them.

Commands to Run
cat > .github/CACHING_GUIDE.md << 'EOF'
# Workflow Caching Guide

## Quick Wins
1. **Always use cache: 'npm'** in setup-node
2. **Parallelize independent jobs** (lint, test, security)
3. **Add path filters** to skip unnecessary runs
4. **Use concurrency** to cancel outdated runs

## When to Use Each Strategy

### Dependency Caching
- Use: Every workflow that installs packages
- Impact: 40-60% faster installs
- Cost: Nearly zero

### Docker Layer Caching
- Use: Workflows building Docker images
- Impact: 50-80% faster builds
- Cost: Some cache storage

### Path Filtering
- Use: Large repos with separate concerns
- Impact: Avoids 30-50% of runs
- Cost: None

### Sparse Checkout
- Use: Very large repos (>1GB)
- Impact: Faster clone for large repos
- Cost: Added complexity

## Monitoring
- Track workflow durations weekly
- Monitor cache hit rates
- Review cache storage usage monthly

git add .github/CACHING_GUIDE.md
git commit -m 'Add caching best practices guide'
git push

What This Does
Consolidate optimization strategies in documentation. Team members can reference when creating workflows. Living document that evolves with project needs.

Expected Outcome
Guide created documenting all optimization techniques learned. Serves as team reference and onboarding material.

Pro Tips
1 Start with easy wins: npm caching, parallelization
2 Add complexity only when justified by gains
3 Monitor before and after each optimization
4 Share knowledge with team in documentation
5 Revisit optimization as project grows

✓ Implement dependency and build caching
✓ Parallelize jobs for faster execution
✓ Skip unnecessary workflow runs with filters
✓ Cache Docker layers for rapid builds
✓ Monitor and measure optimization impact
