201 — Building Images with Dockerfile
Learn to create custom Docker images using Dockerfiles. Understand image layers, caching, and best practices for efficient image builds.

1. Create your first Dockerfile
Set up a simple project directory and create a basic Dockerfile.

Commands to Run
mkdir my-first-image && cd my-first-image

echo FROM ubuntu:22.04 > Dockerfile
echo RUN apt-get update && apt-get install -y curl >> Dockerfile
echo CMD ["echo", "Hello from my custom image!"] >> Dockerfile

cat Dockerfile

What This Does
A Dockerfile is a text file with instructions to build an image. FROM specifies the base image, RUN executes commands during build, and CMD sets the default command when containers start.

Expected Outcome
You'll have a Dockerfile with three instructions. The cat command displays its contents to verify it was created correctly.

2. Build your first custom image
Use docker build to create an image from your Dockerfile.

Commands to Run
docker build -t my-ubuntu:v1 .
docker images my-ubuntu

What This Does
docker build reads the Dockerfile and executes each instruction. The -t flag tags the image with a name. The dot (.) specifies the build context (current directory).

Expected Outcome
You'll see each Dockerfile step execute with output like 'Step 1/3 : FROM ubuntu:22.04'. Finally, your custom image appears in the image list.

Pro Tips
1. The dot (.) is the build context - all files here are available to the build
2. Each RUN command creates a new layer
3. Builds use cache from previous builds to speed up rebuilds
4. Tag format: name:tag or name:version

3. Run a container from your custom image
Test your newly built image by running a container.

Commands to Run
docker run my-ubuntu:v1
docker run my-ubuntu:v1 curl --version

What This Does
The first command runs the default CMD from the Dockerfile. The second overrides the CMD to verify curl is installed.

Expected Outcome
First command outputs 'Hello from my custom image!'. Second shows curl version information, confirming the package was installed during build.

4. Understanding Dockerfile instructions

Commands to Run
cat > Dockerfile << 'EOF'
# Base image
FROM node:18-alpine

# Set working directory
WORKDIR /app

# Copy files
COPY package.json .

# Run commands
RUN npm install

# Copy application code
COPY . .

# Expose port
EXPOSE 3000

# Set environment variable
ENV NODE_ENV=production

# Default command
CMD ["node", "app.js"]
EOF

cat Dockerfile

What This Does
FROM sets base image. WORKDIR sets current directory. COPY adds files from host. RUN executes build commands. EXPOSE documents ports. ENV sets environment variables. CMD defines startup command.

Expected Outcome
A well-structured Dockerfile demonstrating the most common instructions with comments explaining each section.

Pro Tips
1. FROM must be the first instruction
2. WORKDIR creates the directory if it doesn't exist
3. COPY vs ADD: use COPY for simple file copying
4. EXPOSE is documentation - doesn't actually publish ports
5. ENV variables are available at build and runtime
6. Use comments (#) to document your Dockerfile

5. Create a real application image
Build a complete Node.js web application image.

6. Build and run the web application
Build the Node.js application image and run it as a container.

Commands to Run
docker build -t my-node-app:1.0 .
docker run -d -p 3000:3000 --name node-app my-node-app:1.0
docker logs node-app
docker ps

What This Does
Build creates the image with Node.js, dependencies, and app code. Run starts a container with port mapping so you can access the web server from your browser.

Expected Outcome
Build completes successfully. The container runs in background. Logs show 'Server running on port 3000'. Visit http://localhost:3000 to see the app.

Pro Tips
1. The build takes longer first time as it downloads Node.js base image
2. npm install runs inside the container during build
3. Port 3000 inside container maps to port 3000 on your host
4. Check http://localhost:3000 in your browser to verify

Step 7 Understanding image layers and cache
See how Docker uses layers and caching to optimize builds.

Commands to Run
docker history my-node-app:1.0
echo 'console.log("Updated!");' >> app.js
docker build -t my-node-app:1.1 .
docker history my-node-app:1.1

What This Does
Each Dockerfile instruction creates a layer. Docker caches unchanged layers. When you modify app.js, only layers after the COPY . . instruction rebuild.

Expected Outcome
History shows all layers and their sizes. The rebuild is much faster because Docker uses cache for node:18-alpine,
npm install, etc. Only the final layers rebuild. Understanding image layers and cache

Step 8 Optimize layer caching
Restructure your Dockerfile for maximum cache efficiency.

Commands to Run
cat > Dockerfile << 'EOF'
FROM node:18-alpine
WORKDIR /app

# Copy only package.json first
COPY package.json .
RUN npm install

# Copy application code last
COPY app.js .

EXPOSE 3000
ENV NODE_ENV=production
CMD ["node", "app.js"]
EOF

echo 'console.log("Optimized!");' >> app.js
docker build -t my-node-app:1.2 .

What This Does
By copying package.json separately, npm install only reruns when dependencies change. App code changes don't invalidate the npm install cache.

Expected Outcome
The build uses cache for all steps up to and including 'RUN npm install'. Only the 'COPY app.js' step and later steps rebuild.

step 9. Using .dockerignore
See how Docker uses layers and caching to optimize builds.
Exclude unnecessary files from the build context for faster builds.

Commands to Run

cat > .dockerignore << 'EOF'
node_modules
npm-debug.log
.git
.gitignore
.env
*.md
.DS_Store
EOF

echo '# My App' > README.md
mkdir node_modules && touch node_modules/test.js
docker build -t my-node-app:1.3 .
docker run --rm my-node-app:1.3 ls -la /app

What This Does
.dockerignore works like .gitignore - it excludes files from the build context. This speeds up builds and reduces image size by not copying unnecessary files.

Expected Outcome
The build doesn't include node_modules from your host or README.md. The container's /app directory only has the files Docker explicitly copied.

Step 10 Build arguments and customization
Use ARG to parameterize your builds for different environments.

Commands to Run

cat > Dockerfile << 'EOF'
FROM node:18-alpine
ARG NODE_ENV=development
ARG PORT=3000
WORKDIR /app
COPY package.json .
RUN npm install
COPY app.js .

EXPOSE ${PORT}
ENV NODE_ENV=${NODE_ENV}
ENV PORT=${PORT}

CMD ["node", "app.js"]
EOF

docker build -t my-node-app:dev .
docker build -t my-node-app:prod --build-arg NODE_ENV=production --build-arg PORT=8080 .

What This Does
ARG defines build-time variables with optional defaults. Use --build-arg to override them. ARG values can be used in ENV to make them available at runtime.

Expected Outcome
Two images are built with different configurations. The dev image uses defaults, prod uses custom values specified with --build-arg.

Pro Tips
1. ARG is only available during build, ENV is available at runtime
2. Use ARG for build-time customization (versions, features)
3. Use ENV for runtime configuration (ports, modes)
4. Combine them: ENV VAR=${ARG_VAR} to pass build args to runtime

Step 11 Inspect and compare images
Examine differences between your image versions.

Commands to Run
docker images | grep my-node-app
docker inspect my-node-app:dev --format '{{.Config.Env}}'
docker inspect my-node-app:prod --format '{{.Config.Env}}'
docker history my-node-app:prod

What This Does
Compare images to see size, layers, and configuration differences. Inspect shows environment variables set during build.

Expected Outcome
You'll see all versions of my-node-app with their sizes. Environment variables differ between dev and prod images.

Pro Tips
1. Use docker images to compare image sizes
2. Inspect reveals all build-time decisions
3. History shows which layers are shared vs unique
4.Smaller images are faster to pull and more secure

Step 12 Best practices for Dockerfile
Apply industry best practices to your Dockerfile.

Commands to Run

cat > Dockerfile << 'EOF'
# Use specific version tags, not 'latest'
FROM node:18.20-alpine
# Create non-root user
RUN addgroup -g 1001 -S nodejs && adduser -S nodejs -u 1001
WORKDIR /app
# Install dependencies as root
COPY package*.json ./
RUN npm ci --only=production
# Copy app and change ownership
COPY --chown=nodejs:nodejs app.js .
# Switch to non-root user
USER nodejs
EXPOSE 3000
CMD ["node", "app.js"]
EOF

docker build -t my-node-app:secure .
docker run --rm my-node-app:secure whoami

What This Does
Best practices: use specific versions, run as non-root user, use npm ci for reproducible installs, minimize layers, and set proper file ownership.

Expected Outcome
The image builds successfully. The whoami command returns 'nodejs', confirming the container runs as a non-root user.

Pro Tips
1. Never use 'latest' tag in production Dockerfiles
2. Always run containers as non-root for security
3. npm ci is faster and more reliable than npm install
4. Combine RUN commands to reduce layers: RUN cmd1 && cmd2
5. Pin exact versions for reproducible builds

13. Cleanup
Stop containers and optionally remove images to free space.
Commands to Run

docker stop node-app python-app
docker rm node-app python-app
docker images | grep -E 'my-node-app|my-python-app'

What This Does
Clean up running containers. The images remain available for future use. Use 'docker rmi' to remove images if needed.

Expected Outcome
Both containers are stopped and removed. Images are still available in your local image cache.

Pro Tips
1. Use --rm flag when running containers for automatic cleanup
2. Keep images if you'll use them again - they're already built
3. Remove old image versions: docker rmi my-node-app:1.0 my-node-app:1.1
4. Use 'docker system prune' for comprehensive cleanup

✓ Write Dockerfiles with proper syntax and structure
✓ Build custom images from Dockerfiles
✓ Understand and optimize layer caching
✓ Use build arguments for customization
✓ Apply security and best practices
✓ Create images for different languages and frameworks
