202 â€” Advanced Dockerfile Techniques

Step 1 Understanding multi-stage builds
Learn why multi-stage builds are essential for production images.

Commands to Run
mkdir multi-stage-demo && cd multi-stage-demo
Copy
cat > app.go << 'EOF'
package main
import "fmt"
func main() {
    fmt.Println("Hello from Go!")
}
EOF

cat > Dockerfile.single << 'EOF'
FROM golang:1.21
WORKDIR /app
COPY app.go .
RUN go build -o myapp app.go
CMD ["./myapp"]
EOF

docker build -f Dockerfile.single -t go-app:single .
docker images go-app:single

What This Does
A single-stage build includes the entire Go toolchain in the final image. This results in a ~800MB image for a simple binary that could be just a few MB.

Expected Outcome
The image builds successfully but is very large (800MB+) because it includes the full Go compiler and build tools.

Pro Tips
1 Single-stage builds are simpler but inefficient for compiled languages
2 The final image includes build tools, source code, and dependencies
3 Larger images mean slower deployments and larger attack surface

Step 2 Create your first multi-stage build
Use multiple FROM statements to separate build and runtime stages.

Commands to Run
cat > Dockerfile << 'EOF'
# Stage 1: Build stage
FROM golang:1.21 AS builder
WORKDIR /app
COPY app.go .
RUN go build -o myapp app.go

# Stage 2: Runtime stage
FROM alpine:3.19
WORKDIR /app
COPY --from=builder /app/myapp .
CMD ["./myapp"]
EOF

docker build -t go-app:multi .
docker images | grep go-app

What This Does
Multi-stage builds use multiple FROM statements. Only the final stage becomes the image. COPY --from=builder copies artifacts from the build stage.

Expected Outcome
The multi-stage image is ~10MB vs 800MB for single-stage. Both work identically, but multi-stage is 80x smaller!

Pro Tips
1 Name stages with AS keyword for clarity
2 Only the last FROM determines the final image base
3 Copy only what you need from previous stages
4 Ideal for compiled languages (Go, Rust, C++) and JavaScript builds


Step 3 Multi-stage build for Node.js
Apply multi-stage pattern to a Node.js application with build step.
(Multi-stage builds in Docker allow you to create smaller, cleaner, and more efficient images by using multiple FROM statements in a single Dockerfile. Each stage can have its own base image, and you only copy what you need into the final image.)

Commands to Run
cd .. && mkdir node-multi-stage && cd node-multi-stage

cat > package.json << 'EOF'
{
  "name": "app",
  "scripts": { "build": "echo 'Build completed'" },
  "dependencies": { "express": "^4.18.0" },
  "devDependencies": { "nodemon": "^3.0.0" }
}
EOF

cat > server.js << 'EOF'
const express = require('express');
const app = express();
app.get('/', (req, res) => res.send('Multi-stage Node.js!'));
app.listen(3000, () => console.log('Server ready'));
EOF

cat > Dockerfile << 'EOF'
# Build stage
FROM node:18-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build

# Production stage
FROM node:18-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY --from=builder /app/server.js .
USER node
CMD ["node", "server.js"]
EOF

docker build -t node-app:multi .

What This Does
Build stage installs all dependencies (including devDependencies). Production stage only installs production dependencies and copies the built artifacts.

Expected Outcome
The final image doesn't include devDependencies like nodemon, reducing size and attack surface.

Pro Tips
1 Separate build and runtime dependencies
2 Build tools (webpack, typescript) stay in build stage
3 Production stage is smaller and more secure
4 Use npm ci in production stage for reproducible installs

step 5 Adding health checks
Configure Docker to monitor container health automatically.

Commands to Run

FROM node:18-alpine
WORKDIR /app
# Install curl for health checks
RUN apk add --no-cache curl
COPY package*.json ./
RUN npm ci --only=production
COPY server.js .
# Health check configuration
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:3000/ || exit 1
USER node
EXPOSE 3000
CMD ["node", "server.js"]

docker build -t node-app:health .
docker run -d -p 3000:3000 --name health-test node-app:health
sleep 10 && docker ps
docker inspect health-test --format='{{.State.Health.Status}}'

What This Does
HEALTHCHECK tells Docker how to test if the container is working. It runs the check command periodically. Status can be: starting, healthy, or unhealthy.

Expected Outcome
After the start period, the container shows 'healthy' status. Docker ps shows health status in STATUS column.

Pro Tips
1 --interval: how often to check (default 30s)
2 --timeout: how long to wait for response (default 30s)
3 --start-period: grace period before first check (default 0s)
4 --retries: failures needed to mark unhealthy (default 3)
5 Exit 0 = healthy, exit 1 = unhealthy
6 Orchestrators like Kubernetes can use this to restart unhealthy containers

in local: New-Item -ItemType Directory -Force -Path config, logs (mkdir -p config logs)
New-Item -ItemType File -Force -Path config/app.yml, config/db.yml, logs/app.log (touch config/app.yml config/db.yml logs/app.log)

Step 5 Advanced COPY patterns
Use wildcards, multiple sources, and ownership in COPY instructions.

Commands to Run
mkdir -p config logs
touch config/app.yml config/db.yml logs/app.log
in local: New-Item -ItemType Directory -Force -Path config, logs (mkdir -p config logs)
New-Item -ItemType File -Force -Path config/app.yml, config/db.yml, logs/app.log (touch config/app.yml config/db.yml logs/app.log)

FROM node:18-alpine
# Create user first
RUN addgroup -g 1001 appgroup && adduser -u 1001 -G appgroup -s /bin/sh -D appuser
WORKDIR /app
# Copy with wildcards
COPY config/*.yml /app/config/
# Copy multiple sources
COPY package.json server.js ./
# Copy with ownership
COPY --chown=appuser:appgroup logs/ /app/logs/
# Verify ownership
RUN ls -la /app/logs
USER appuser
CMD ["node", "server.js"]

docker build -t node-app:copy .
docker run --rm node-app:copy ls -la /app

What This Does
COPY supports wildcards, multiple sources, and --chown to set ownership. This avoids separate RUN chown commands, reducing layers.

Expected Outcome
Files are copied with correct ownership. The logs directory is owned by appuser:appgroup from the start.

Pro Tips
1 Use wildcards for flexible patterns: *.yml, *.json
2 --chown avoids extra RUN chown commands (saves a layer)
3 Paths with spaces need quotes: COPY "my file.txt" .
4 COPY fails if source doesn't exist (unlike ADD)
5 Always prefer COPY over ADD unless you need ADD's special features

Step 6 Optimizing RUN commands
Combine commands and clean up in the same layer to reduce image size.

Commands to Run
cat > Dockerfile.bad << 'EOF'
FROM ubuntu:22.04
RUN apt-get update
RUN apt-get install -y curl
RUN apt-get install -y wget
RUN apt-get install -y vim

cat > Dockerfile.good << 'EOF'
FROM ubuntu:22.04
RUN apt-get update && apt-get install -y \
    curl \
    wget \
    vim \
  && rm -rf /var/lib/apt/lists/*

docker build -f Dockerfile.bad -t ubuntu:bad .
docker build -f Dockerfile.good -t ubuntu:good .
docker images | grep ubuntu

What This Does
Each RUN creates a layer. Combining commands reduces layers. Cleaning package manager cache in the same RUN prevents it from being in the final image.

Expected Outcome
The 'good' image is significantly smaller because cache is cleaned in the same layer where packages are installed.

Pro Tips
1 Combine related RUN commands with && and \
2 Clean up in the same layer: rm -rf /var/lib/apt/lists/*
3 For apk: apk add --no-cache (doesn't create cache)
4 For yum: yum clean all
5 Order commands by likelihood of change for better caching
6 Use \ for line continuation to keep Dockerfile readable

Step 7 Using ENTRYPOINT vs CMD
Understand the difference and how to use them together.

Commands to Run
cat > Dockerfile.cmd << 'EOF'
FROM alpine:3.19
CMD ["echo", "Hello"]
EOF

cat > Dockerfile.entry << 'EOF'
FROM alpine:3.19
ENTRYPOINT ["echo", "Hello"]
EOF

cat > Dockerfile.both << 'EOF'
FROM alpine:3.19
ENTRYPOINT ["echo"]
CMD ["Hello"]
EOF

docker build -f Dockerfile.cmd -t test:cmd .
docker build -f Dockerfile.entry -t test:entry .
docker build -f Dockerfile.both -t test:both .
docker run test:cmd
docker run test:cmd World
docker run test:entry
docker run test:entry World
docker run test:both
docker run test:both World

What This Does
CMD is easily overridden. ENTRYPOINT is the main command. When both are used, CMD provides default arguments to ENTRYPOINT.

Expected Outcome
CMD-only: 'World' replaces entire command. ENTRYPOINT-only: 'World' is added as argument. Both: 'World' replaces default 'Hello'.

Pro Tips
1 Use ENTRYPOINT for the main executable
2 Use CMD for default arguments that users might override
3 Common pattern: ENTRYPOINT ["app"], CMD ["--help"]
4 Override ENTRYPOINT: docker run --entrypoint bash image
5 Prefer exec form ["cmd", "arg"] over shell form cmd arg

Step 8 Handling signals properly
Ensure your application handles shutdown signals gracefully.

Commands to Run
cat > app.sh << 'EOF'
#!/bin/sh
trap "echo 'Shutting down...'; exit 0" SIGTERM SIGINT
echo "App started"
while true; do
  sleep 1
done
EOF

cat > Dockerfile << 'EOF'
FROM alpine:3.19
WORKDIR /app
COPY app.sh .
RUN chmod +x app.sh
# Use exec form to ensure proper signal handling
CMD ["./app.sh"]
EOF

docker build -t signal-test .
docker run --name signal-demo signal-test &
sleep 3 && docker stop signal-demo
docker logs signal-demo

What This Does
Using exec form of CMD ensures signals reach your application. The trap command in shell scripts handles SIGTERM for graceful shutdown.

Expected Outcome
When stopped, the container logs 'Shutting down...' before exiting, showing it received and handled the signal properly.

Pro Tips
1 Always use exec form: CMD ["app"] not CMD app
2 Shell form starts /bin/sh which doesn't forward signals
3 In Node.js, handle process.on('SIGTERM')
4 In Go, use signal.Notify()
5 Docker sends SIGTERM, waits 10s, then SIGKILL
6 Graceful shutdown prevents data loss

Step 9 Build-time secrets handling
Safely use secrets during build without leaving them in the image.

Commands to Run
cd .. && mkdir secrets-demo && cd secrets-demo
echo 'SECRET_TOKEN=my-secret-token' > secret.txt

cat > Dockerfile << 'EOF'
# syntax=docker/dockerfile:1
FROM alpine:3.19
WORKDIR /app
# BAD: Secret ends up in layer
# COPY secret.txt .
# RUN cat secret.txt && rm secret.txt
# GOOD: Use secret mount
RUN --mount=type=secret,id=mysecret \
    cat /run/secrets/mysecret > config.txt
CMD ["cat", "config.txt"]
EOF

DOCKER_BUILDKIT=1 docker build --secret id=mysecret,src=secret.txt -t secret-test .
docker history secret-test

What This Does
Build secrets are mounted during build but never stored in layers. This prevents secrets from appearing in the image history.

Expected Outcome
The secret is used during build but 'docker history' doesn't show it. The secret file isn't in the final image layers.

Pro Tips
1 Requires BuildKit (DOCKER_BUILDKIT=1)
2 Secrets are mounted at /run/secrets/<id>
3 Never COPY secrets and delete them - they stay in layers!
4 Use secret mounts for API tokens, passwords, SSH keys
5 Combine with ARG for non-sensitive build parameters

Step 10 Cache mounts for faster builds
Use cache mounts to persist package manager caches across builds.

Commands to Run
cd .. && mkdir cache-demo && cd cache-demo

cat > Dockerfile << 'EOF'
# syntax=docker/dockerfile:1
FROM node:18-alpine
WORKDIR /app
COPY package*.json ./

# Cache npm's download cache across builds
RUN --mount=type=cache,target=/root/.npm \
    npm ci --only=production

COPY . .
CMD ["node", "index.js"]
EOF
Copy
cat > package.json << 'EOF'
{
  "dependencies": {
    "express": "^4.18.0",
    "lodash": "^4.17.21",
    "axios": "^1.6.0"
  }
}
EOF

echo 'console.log("Ready");' > index.js
DOCKER_BUILDKIT=1 docker build -t cache-test:v1 .  (in local: $env DOCKER_BUILDKIT=1)
echo 'console.log("Updated");' > index.js
DOCKER_BUILDKIT=1 docker build -t cache-test:v2 .

What This Does
Cache mounts persist directories across builds. npm packages are cached, so the second build doesn't re-download packages.

Expected Outcome
First build downloads packages normally. Second build is much faster as packages come from cache.

Pro Tips
1 Common targets: /root/.npm (npm), /root/.cache/pip (Python), /go/pkg (Go)
2 Cache mounts speed up development iterations significantly
3 Caches are local to the machine running the build
4 Use with CI/CD for faster pipeline builds
5 Combine with layer caching for maximum efficiency

Step 11 Multi-platform builds
Build images that work on different CPU architectures.

Commands to Run
cd .. && mkdir platform-demo && cd platform-demo

cat > Dockerfile << 'EOF'
FROM --platform=$BUILDPLATFORM golang:1.21-alpine AS builder
ARG TARGETPLATFORM
ARG BUILDPLATFORM
RUN echo "Building on $BUILDPLATFORM for $TARGETPLATFORM"
WORKDIR /app
COPY app.go .
RUN go build -o myapp app.go

FROM alpine:3.19
COPY --from=builder /app/myapp .
CMD ["./myapp"]
EOF

echo 'package main
import "fmt"
func main() { fmt.Println("Hello!") }' > app.go

docker buildx ls
docker buildx build --platform linux/amd64,linux/arm64 -t multiarch:latest .

What This Does
BuildX builds for multiple architectures in one command. BUILDPLATFORM is where you're building, TARGETPLATFORM is where the image will run.

Expected Outcome
Docker builds images for both AMD64 (Intel/AMD) and ARM64 (Apple Silicon, ARM servers). The same Dockerfile works for both.

Pro Tips
1 Essential for supporting Mac M1/M2 and ARM servers
2 Use --platform flag to specify target architectures
3 BuildX is included in Docker Desktop by default
4 To push: add --push flag
5 Docker Hub stores multi-arch images as manifests


12.Step  Debugging builds with target stages (Build only specific stages for debugging and testing.)
 Target stages let you build and test one step of your Dockerfile at a time, instead of the whole thing.

Commands to Run
cd .. && mkdir debug-demo && cd debug-demo

cat > Dockerfile << 'EOF'
FROM node:18-alpine AS base
WORKDIR /app
COPY package*.json ./

FROM base AS development
RUN npm install
COPY . .
CMD ["npm", "run", "dev"]

FROM base AS production
RUN npm ci --only=production
COPY . .
CMD ["node", "server.js"]
EOF

cat > package.json << 'EOF'
{
  "scripts": { "dev": "echo 'Dev mode'" },
  "dependencies": { "express": "^4.18.0" }
}
EOF

touch server.js
docker build --target development -t app:dev .
docker build --target production -t app:prod .
docker images | grep app

What This Does
Name stages with AS and use --target to build specific stages. Build stops at the target stage, ignoring later stages.

Expected Outcome
Two images are created: dev includes devDependencies, prod doesn't. Both share the base stage layers.

Pro Tips
1 Use for development vs production builds
2 Common stages: deps, build, test, production
3 Speeds up builds by skipping unnecessary stages
4 Great for CI/CD: build test stage to run tests
5 Shared early stages benefit from layer caching

Step 13 Production-ready image checklist
Apply all best practices to create a production-ready image.

Commands to Run
cd .. && mkdir production-ready && cd production-ready

cat > app.js << 'EOF'
const express = require('express');
const app = express();
app.get('/health', (req, res) => res.json({ status: 'ok' }));
app.listen(3000, '0.0.0.0', () => console.log('Ready'));
process.on('SIGTERM', () => { console.log('Shutdown'); process.exit(0); });
EOF

cat > package.json << 'EOF'
{ "dependencies": { "express": "4.18.2" } }
EOF

cat > Dockerfile << 'EOF'
# syntax=docker/dockerfile:1
# Use specific versions
FROM node:18.20-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN --mount=type=cache,target=/root/.npm npm ci
COPY . .

# Production stage
FROM node:18.20-alpine
WORKDIR /app

# Install security updates
RUN apk upgrade --no-cache && apk add --no-cache curl

# Create non-root user
RUN addgroup -g 1001 nodejs && adduser -u 1001 -G nodejs -s /bin/sh -D nodejs

COPY package*.json ./
RUN npm ci --only=production && npm cache clean --force

COPY --from=builder --chown=nodejs:nodejs /app/app.js .

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:3000/health || exit 1

USER nodejs
EXPOSE 3000
CMD ["node", "app.js"]
EOF

DOCKER_BUILDKIT=1 docker build -t production-app .
docker run -d -p 3000:3000 --name prod-test production-app
sleep 10 && docker inspect prod-test --format='{{.State.Health.Status}}'
docker stop prod-test && docker rm prod-test

What This Does
A production-ready image: uses specific versions, runs as non-root, has health checks, handles signals, optimizes layers, and includes security updates.

Expected Outcome
Image builds efficiently, runs securely as non-root user, reports healthy status, and shuts down gracefully.
